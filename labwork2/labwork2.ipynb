{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B-VZdoLoV1H",
        "outputId": "cfedd7b3-a708-4d29-a9d1-d906763a3ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numba-cuda in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numba>=0.59.1 in /usr/local/lib/python3.12/dist-packages (from numba-cuda) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.59.1->numba-cuda) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.12/dist-packages (from numba>=0.59.1->numba-cuda) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numba-cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba.cuda.cudadrv import enums\n",
        "from numba import cuda\n",
        "\n",
        "cuda.detect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6FyBkF7pY_r",
        "outputId": "85e986a9-ef9f-4a76-b17e-b857b607fa8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 CUDA devices\n",
            "id 0             b'Tesla T4'                              [SUPPORTED]\n",
            "                      Compute Capability: 7.5\n",
            "                           PCI Device ID: 4\n",
            "                              PCI Bus ID: 0\n",
            "                                    UUID: GPU-1376e51e-3a62-e0b5-df6b-acec1af4496f\n",
            "                                Watchdog: Disabled\n",
            "             FP32/FP64 Performance Ratio: 32\n",
            "Summary:\n",
            "\t1/1 devices are supported\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = cuda.get_current_device()\n",
        "multi_processor = getattr(device, 'MULTIPROCESSOR_COUNT')\n",
        "print(multi_processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEBPIDOzp2Wy",
        "outputId": "72663a89-815b-4007-cac6-62aee88642ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_cap = device.compute_capability\n",
        "print(compute_cap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMAGNczpyhb9",
        "outputId": "5ea5b59a-b428-4697-82e6-ab826130b4d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.5 -> https://developer.nvidia.com/cuda-gpus -> 7.5 seems to be ampere\n",
        "# https://en.wikipedia.org/wiki/Ampere_(microarchitecture) -> 64 cores/sm\n",
        "core_per_sm = 64\n",
        "total_cores = multi_processor * core_per_sm\n",
        "print(total_cores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y81lOD9yxES-",
        "outputId": "725fb447-7470-44b7-b735-b44d0e11bf73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_info = cuda.current_context().get_memory_info()\n",
        "total = getattr(memory_info, 'total')\n",
        "print(str(total/1024/1024) + \"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POrFis-xrDBH",
        "outputId": "ea5954c6-28a5-4abd-a189-9f2159a25a83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15095.0625MB\n"
          ]
        }
      ]
    }
  ]
}